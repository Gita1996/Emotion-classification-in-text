{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d939dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_version = 'microsoft/deberta-v2-xlarge-mnli'\n",
    "model = AutoModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "\n",
    "# Inputs\n",
    "sentence_a = \"When I found a bristle in the liver paste tube.\"\n",
    "sentence_a = \"At a gathering I found myself involuntarily sitting next to two people who expressed opinions that I considered very low and discriminating.\"\n",
    "#sentence_a=\"When I had just moved into my new appartment I found a ventilator in the kitchen. I was going to clean it when I found that the drum was full of mud and slime. I felt disgusted.\"\n",
    "#sentence_a= \"Grovelling people.\"\n",
    "sentence_b = \"This text expresses disgust\"\n",
    "#sentence_b = \"disgust\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids']  # Indicates Sentence A (0) and Sentence B (1)\n",
    "\n",
    "# Get model output and attention\n",
    "outputs = model(input_ids, token_type_ids=token_type_ids)\n",
    "attention = outputs[-1]  # Extract attention weights\n",
    "\n",
    "# Convert to tensor for processing\n",
    "attention = torch.stack(attention)\n",
    "\n",
    "# Identify token position of \"disgust\" in the input\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "disgust_idx = len(token_type_ids[0]) - 2  # Position of \"disgust\" token\n",
    "\n",
    "# Extract attention scores for the \"disgust\" token across all heads\n",
    "# Shape: (num_layers, num_heads, len_sequence)\n",
    "sentence_end = len(token_type_ids[0])  # Total length of the sentence\n",
    "template_end = len(token_type_ids[0])-2\n",
    "sentence_to_template = attention[:, 0, :, :, disgust_idx].detach().cpu().numpy()  # (num_layers, num_heads, len_sequence)\n",
    "\n",
    "sentence_to_template = attention[:, 0, :, template_end, :sentence_end].detach().cpu().numpy() \n",
    "# Aggregate attention across heads for each token\n",
    "# Taking average attention across all heads\n",
    "average_attention = np.mean(sentence_to_template[23], axis=0)  # Use layer 23 (last layer)\n",
    "ll=len(average_attention)\n",
    "print(average_attention[0])\n",
    "\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    average_attention.reshape(-1, 1),  # Ensure 2D input\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    ax=ax,\n",
    "    xticklabels=[\"disgust\"],  # Only \"disgust\" on X-axis\n",
    "    yticklabels=tokens,  # Tokens on Y-axis\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "ax.set_title(\"Average Attention to 'disgust' (Layer 23)\")\n",
    "ax.set_ylabel(\"Tokens\")\n",
    "ax.set_xlabel(\"Query Token ('disgust')\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8811986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_version = 'microsoft/deberta-v2-xlarge-mnli'\n",
    "model = AutoModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "df=pd.read_csv(\"anger_emotion_Deberta_Tec.csv\")\n",
    "txt=df['text'].tolist()\n",
    "\n",
    "\n",
    "# Inputs\n",
    "sentence_a = \"When I found a bristle in the liver paste tube.\"\n",
    "sentence_a = \"At a gathering I found myself involuntarily sitting next to two people who expressed opinions that I considered very low and discriminating.\"\n",
    "#sentence_a=\"When I had just moved into my new appartment I found a ventilator in the kitchen. I was going to clean it when I found that the drum was full of mud and slime. I felt disgusted.\"\n",
    "#sentence_a= \"Grovelling people.\"\n",
    "#sentence_b = \"This text expresses disgust\"\n",
    "#sentence_b = \"disgust\"\n",
    "count=0\n",
    "for m in txt:\n",
    "# Tokenize input\n",
    "  sentence_b = \"anger\"\n",
    "  inputs = tokenizer.encode_plus(m, sentence_b, return_tensors='pt')\n",
    "  input_ids = inputs['input_ids']\n",
    "  token_type_ids = inputs['token_type_ids']  # Indicates Sentence A (0) and Sentence B (1)\n",
    "\n",
    "  # Get model output and attention\n",
    "  outputs = model(input_ids, token_type_ids=token_type_ids)\n",
    "  attention = outputs[-1]  # Extract attention weights\n",
    "\n",
    "  # Convert to tensor for processing\n",
    "  attention = torch.stack(attention)\n",
    "\n",
    "  # Identify token position of \"disgust\" in the input\n",
    "  tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "  disgust_idx = len(token_type_ids[0]) - 2  # Position of \"disgust\" token\n",
    "\n",
    "  # Extract attention scores for the \"disgust\" token across all heads\n",
    "  # Shape: (num_layers, num_heads, len_sequence)\n",
    "  sentence_end = len(token_type_ids[0])  # Total length of the sentence\n",
    "  template_end = len(token_type_ids[0])-2\n",
    "  sentence_to_template = attention[:, 0, :, :, disgust_idx].detach().cpu().numpy()  # (num_layers, num_heads, len_sequence)\n",
    "\n",
    "  sentence_to_template = attention[:, 0, :, template_end, :sentence_end].detach().cpu().numpy() \n",
    "  # Aggregate attention across heads for each token\n",
    "  # Taking average attention across all heads\n",
    "  average_attention = np.mean(sentence_to_template[23], axis=0)  # Use layer 23 (last layer)\n",
    "#  ll=len(average_attention)\n",
    "#  print(average_attention[0])\n",
    "  cls1=average_attention[0]\n",
    "  #########\n",
    "  sentence_b = \"This text expresses anger\"\n",
    "  inputs = tokenizer.encode_plus(m, sentence_b, return_tensors='pt')\n",
    "  input_ids = inputs['input_ids']\n",
    "  token_type_ids = inputs['token_type_ids']  # Indicates Sentence A (0) and Sentence B (1)\n",
    "  sentence_a_end = token_type_ids[0].tolist().index(1)\n",
    "  # Get model output and attention\n",
    "  outputs = model(input_ids, token_type_ids=token_type_ids)\n",
    "  attention = outputs[-1]  # Extract attention weights\n",
    "\n",
    "  # Convert to tensor for processing\n",
    "  attention = torch.stack(attention)\n",
    "\n",
    "  # Identify token position of \"disgust\" in the input\n",
    "  tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "  disgust_idx = len(token_type_ids[0]) - 2  # Position of \"disgust\" token\n",
    "\n",
    "  # Extract attention scores for the \"disgust\" token across all heads\n",
    "  # Shape: (num_layers, num_heads, len_sequence)\n",
    "  sentence_end = len(token_type_ids[0])  # Total length of the sentence\n",
    "  template_end = len(token_type_ids[0])-2\n",
    "  sentence_to_template = attention[:, 0, :, :, disgust_idx].detach().cpu().numpy()  # (num_layers, num_heads, len_sequence)\n",
    "\n",
    "  sentence_to_template = attention[:, 0, :, template_end, :sentence_end].detach().cpu().numpy() \n",
    "  # Aggregate attention across heads for each token\n",
    "  # Taking average attention across all heads\n",
    "  average_attention = np.mean(sentence_to_template[23], axis=0)  # Use layer 23 (last layer)\n",
    "#  ll=len(average_attention)\n",
    "#  print(average_attention[0])\n",
    "  cls2=average_attention[0]\n",
    "  if cls2>=cls1:\n",
    "    count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
